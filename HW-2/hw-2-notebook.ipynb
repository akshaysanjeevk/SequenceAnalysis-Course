{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment#2- Hidden Markov Model \n",
    "Submitted by:\n",
    "Akshay Sanjeev. \n",
    "\n",
    "\n",
    "A version of this is uploaded to : https://github.com/askay-sanjeev/seqanalysis-homeworks/tree/main/HW-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hw2_fns as HMM\n",
    "from numpy.random import choice as choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the question\n",
    "S = ['H', 'T']\n",
    "T = 3\n",
    "a = np.array([[  0,  .5,  .5], #transition probabilities\n",
    "              [.01, .94, .05],\n",
    "              [.01, .05, .94]])\n",
    "e = np.array([[.5, .5], #emission probabilities\n",
    "              [.8, .2]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HMM Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hmm_gen(S, T, a, e):\n",
    "    '''\n",
    "    This notation will be followed for the rest of the notebook:\n",
    "    S = observable states. e.g, {Head, Tail}\n",
    "    T = hidden states. e.g, {0(init/term), 1(Fair), 2(Biased)}\n",
    "    a = transition probabilites for hidden states\n",
    "    e = emission probabilities of hidden states\n",
    "    OUTPUT:\n",
    "    pi = hidden state chain\n",
    "    x = observable state chain\n",
    "    '''\n",
    "    T =  np.arange(T)\n",
    "    pi = []\n",
    "    x = []\n",
    "    pi.append(choose(T[1:], p=a[0, 1: len(T)]))\n",
    "    x.append(choose(S, p=e[pi[0]-1, :]))\n",
    "    while pi[-1] != 0:\n",
    "        pi.append(choose(T, p=a[pi[-1], :]))\n",
    "        x.append(choose(S, p=e[pi[-1]-1, :]))\n",
    "    pi = [int(p) for p in pi]\n",
    "    x = [str(q) for q in x]\n",
    "    return pi, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of generated sequence = 117\n",
      "Hidden state seq: \n",
      " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "Observable state seq: \n",
      " ['T', 'H', 'H', 'H', 'H', 'T', 'T', 'H', 'T', 'H', 'T', 'T', 'H', 'T', 'H', 'H', 'H', 'H', 'H', 'T', 'T', 'H', 'T', 'H', 'T', 'H', 'H', 'T', 'H', 'T', 'H', 'T', 'T', 'H', 'H', 'T', 'H', 'H', 'H', 'T', 'T', 'T', 'H', 'H', 'T', 'T', 'T', 'T', 'H', 'T', 'T', 'T', 'H', 'T', 'T', 'T', 'H', 'T', 'H', 'H', 'T', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'T', 'T', 'T', 'H', 'T', 'H', 'T', 'H', 'H', 'T', 'H', 'T', 'T', 'T', 'H', 'T', 'T', 'H', 'H', 'H', 'T', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'T', 'H', 'H', 'T', 'H', 'H', 'H', 'T', 'H', 'T', 'T', 'T', 'H', 'H']\n"
     ]
    }
   ],
   "source": [
    "# Example \n",
    "pi,x = hmm_gen(S, T, a, e)\n",
    "print(f'length of generated sequence = {len(x)}')\n",
    "print(f'Hidden state seq: \\n {pi}')\n",
    "print(f'Observable state seq: \\n {x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(x, S, T, a, e):#x is obs, h is hid\n",
    "    obsstates = {S[0]: 0, S[1] : 1}\n",
    "    v = np.zeros((len(x), T-1))\n",
    "    v[0, :] = a[0, 1:]\n",
    "    path = []\n",
    "    for xi in range(1,len(x)):\n",
    "        for hi in range(T-1):\n",
    "            v[xi, hi] = np.max([\n",
    "                v[xi-1, i] * a[i, hi] * e[hi, obsstates[x[xi]]]\n",
    "                for i in range(T-1)\n",
    "            ])\n",
    "        path.append(np.argmax(v[xi, :]))\n",
    "    return [int(i) for i in path]\n",
    "\n",
    "def match(pi1, pi2):\n",
    "    score = 0\n",
    "    for i in range(len(pi1)):\n",
    "        if pi1[i] == pi2[i]:\n",
    "            score+=1\n",
    "    return score/len(pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.62% of the inferred seq matches with the original hidden state sequence.\n"
     ]
    }
   ],
   "source": [
    "path = Viterbi(x, S, T, a, e)\n",
    "matchfrac = HMM.match(path, pi)\n",
    "print(f'{matchfrac*100:.2f}% of the inferred seq matches with the original hidden state sequence.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward(x, S, T, a, e, matrix=False):\n",
    "    obs_index = {obs: i for i, obs in enumerate(S)}\n",
    "    alpha = np.zeros((len(x), T-1))\n",
    "    for i in range(T-1):\n",
    "        alpha[0, i] = a[0, i+1] * e[i, obs_index[x[0]]]\n",
    "    for xi in range(1, len(x)):\n",
    "        obs_idx = obs_index[x[xi]]\n",
    "        for hi in range(T-1):\n",
    "            alpha[xi, hi] = np.sum(\n",
    "                alpha[xi-1, :] * a[1:, hi+1] * e[hi, obs_idx])\n",
    "    if matrix == False:\n",
    "        return np.sum(alpha[-1, :])\n",
    "    if matrix == True:\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The likelihood of input sequence = 8.499619488270787e-36\n"
     ]
    }
   ],
   "source": [
    "f_lk = Forward(x, S, T, a, e)\n",
    "print(f'The likelihood of input sequence = {f_lk}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Backward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backward(x, S, T, a, e, matrix=False):\n",
    "    obs_index = {s: i for i, s in enumerate(S)}\n",
    "    N = T - 1\n",
    "    beta = np.zeros((len(x), T))\n",
    "    beta[-1, 1:] = 1  \n",
    "    for xi in reversed(range(len(x)-1)):\n",
    "        for hi in range(1, T):\n",
    "            beta[xi, hi] = np.sum(\n",
    "                beta[xi+1, 1:] * a[hi, 1:] * e[:, obs_index[x[xi+1]]])\n",
    "    likelihood = np.sum(a[0, 1:] * e[:, obs_index[x[0]]] * beta[0, 1:])\n",
    "    if matrix == False:\n",
    "        return likelihood\n",
    "    if matrix == True:\n",
    "        return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The likelihood of input sequence = 8.499619488270795e-36\n"
     ]
    }
   ],
   "source": [
    "b_lk = Backward(x, S, T, a, e)\n",
    "print(f'The likelihood of input sequence = {b_lk}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Posterior Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ForwardBackward(x, S, T, a, e):\n",
    "    alpha = Forward(x, S, T, a, e, matrix=True)\n",
    "    beta = Backward(x, S, T, a, e, matrix=True)\n",
    "\n",
    "    posterior = np.zeros_like(alpha)\n",
    "    for xi in range(len(x)):\n",
    "        ab = alpha[xi] * beta[xi, 1:]\n",
    "        posterior[xi] = ab / np.sum(ab)\n",
    "    \n",
    "    return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The posterior probabilities of hidden states at 10:\n",
      " p(Fair) = 0.892 \n",
      " p(Biased) = 0.108\n"
     ]
    }
   ],
   "source": [
    "post = ForwardBackward(x, S, T, a, e)\n",
    "\n",
    "#specify the state at which you want to compute the posterior probability\n",
    "i = 10\n",
    "print(f'The posterior probabilities of hidden states at {i}:\\n p(Fair) = {post[i][0]:.3f} \\n p(Biased) = {post[i][1]:.3f}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

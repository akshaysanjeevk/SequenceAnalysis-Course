{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment#2- Hidden Markov Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hw2_fns import hmm_gen, Viterbi, match, Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the question\n",
    "S = ['H', 'T']\n",
    "T = 3\n",
    "a = np.array([[  0,  .5,  .5], #transition probabilities\n",
    "              [.01, .94, .05],\n",
    "              [.01, .05, .94]])\n",
    "e = np.array([[.5, .5], #emission probabilities\n",
    "              [.8, .2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HMM Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of generated sequence = 45\n",
      "Hidden state seq: \n",
      " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0]\n",
      "Observable state seq: \n",
      " ['T', 'T', 'T', 'T', 'H', 'H', 'H', 'H', 'H', 'T', 'H', 'T', 'T', 'T', 'H', 'T', 'H', 'T', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'T', 'H', 'H', 'T', 'T', 'T', 'H', 'T', 'H', 'H', 'H', 'H', 'T', 'H', 'H', 'H', 'H', 'H']\n"
     ]
    }
   ],
   "source": [
    "# Example \n",
    "pi,x = hmm_gen(S, T, a, e)\n",
    "print(f'length of generated sequence = {len(x)}')\n",
    "print(f'Hidden state seq: \\n {pi}')\n",
    "print(f'Observable state seq: \\n {x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.91% of the inferred seq matches with the original hidden state sequence.\n"
     ]
    }
   ],
   "source": [
    "# Example from the question\n",
    "path = Viterbi(x, S, T, a, e)\n",
    "matchfrac = match(path, pi)\n",
    "print(f'{matchfrac*100:.2f}% of the inferred seq matches with the original hidden state sequence.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The likelihood of input sequence = 4.623937530261553e-15\n"
     ]
    }
   ],
   "source": [
    "from hw2_fns import Forward\n",
    "likelihood = Forward(x, S, T, a, e)\n",
    "print(f'The likelihood of input sequence = {likelihood}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Backward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.arange(T)\n",
    "obsstates = {S[0]: 0, S[1] : 1}\n",
    "alpha = np.zeros((len(x), len(T)-1))\n",
    "alpha[:, 0] = 0\n",
    "alpha[0, :] = a[0, 1:]\n",
    "path = []\n",
    "for xi in range(1,len(x)):\n",
    "    for hi in range(len(T)-1):\n",
    "        k = []\n",
    "        for hi2 in range(len(T)-1):\n",
    "            p_trans = a[hi, hi2]\n",
    "            p_emssn = e[hi-1, obsstates[x[xi]]]\n",
    "            k.append(alpha[xi-1, hi2]*p_trans*p_emssn)\n",
    "        alpha[xi, hi] = np.sum(k)\n",
    "likelihood =  np.sum(alpha[-1, :])\n",
    "return likelihood"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
